{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPARQLing to local Triple Store\n",
    "\n",
    "Within this Jupyter Notebook script, a local (emulated) triple store is created using the OWLready2 Python package to perform SPARQL queries to the example dataset provided, which can be used for quick data checks. \n",
    "Accordingly, within this script, necessary and useful libraries are imported and helper functions are implemented, first. Afterwards, some example SPARQL queries are performed.\n",
    "The SPARQL queries are read in from separately created files that contain only the SPARQL query body (text of SPARQL query). They can be found in the dedicated [SPARQL folder]() within this repository.\n",
    "\n",
    "They follow the general pattern of SPARQL queries:\n",
    "\n",
    "```SPARQL\n",
    "PREFIX ex: <https://example.org/my/namespace/>\n",
    "\n",
    "SELECT ?s ?p ?o\n",
    "WHERE {\n",
    "    ?s ?p ?o\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of relevant packages | Definition of helper function(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Import relevant and useful packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import owlready2 as or2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of helper functions\n",
    "# Function to transform inputs to IRIs.\n",
    "def to_iri(input):\n",
    "    try:\n",
    "        return input.iri\n",
    "    except:\n",
    "        pass\n",
    "    return input\n",
    "\n",
    "# Function to write the result of a SPARQL query into a (pandas) data frame.\n",
    "def sparql_result_to_df(res):\n",
    "    l = []\n",
    "    for row in res:\n",
    "        r = [ to_iri(item)  for item in row]\n",
    "        l.append(r)\n",
    "    return pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition of Sources\n",
    "\n",
    "In the following cell, the sources of ontologies to be read in (parsed) as well as of the A-Box to be queried are specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define links to ontologies, files, etc. to be loaded in the local triple store\n",
    "link_PMDco = \"https://materialdigital.github.io/core-ontology/ontology.rdf\" # PMD Core Ontology (PMDco) hosted on corresponding GitHub repository\n",
    "link_ontoFNCT = \"https://MarkusSchilling.github.io/ontoFNCT/ontology.rdf\" # FNCT Ontology (ontoFNCT) hosted on corresponding GitHub repository\n",
    "link_data = \"https://raw.githubusercontent.com/MarkusSchilling/ontoFNCT/main/analysis/ontoFNCT_exemplary_data_PE-HD.rdf\" # Example Dataset hosted on corresponding GitHub repository\n",
    "\n",
    "triple_store = or2.World()\n",
    "triple_store.get_ontology(link_PMDco).load()\n",
    "triple_store.get_ontology(link_ontoFNCT).load()\n",
    "triple_store.get_ontology(link_data).load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specification of SPARQL Queries\n",
    "\n",
    "In the following cells, some example SPARQL queries are selected (corresponding files). The queries contained in these files will be used for querying in the subsequent cell(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the location of files containing SPARQL queries that are supposed to be run\n",
    "link_SPARQL_query_count_all_entities = 'SPARQL\\count_all_entities_in_triple_store.sparql' # Count all triples that can be found in the dataset\n",
    "link_SPARQL_query_count_number_FNCT_tests = 'SPARQL\\count_number_of_FNCT_tests.sparql' # Query for the number of instances of type \"FNCT\" in the dataset (number of FNCT tests included)\n",
    "link_SPARQL_query_select_all_materials_tested = 'SPARQL\\select_all_materials_tested.sparql' # Query to obtain the names of materials tested\n",
    "link_SPARQL_query_FNCT_results = 'SPARQL\\FNCT_results.sparql' # Query to obtain material names, media measured in and the FNCT results considering time to failure and the measured stress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform SPARQL Queries\n",
    "\n",
    "# First example SPARQL Query\n",
    "# Open the file and read the SPARQL query\n",
    "with open(link_SPARQL_query_count_all_entities, 'r') as file:\n",
    "    query = file.read()\n",
    "# Execute the SPARQL query\n",
    "res = triple_store.sparql(query)\n",
    "# Convert the result to a DataFrame\n",
    "data_count_all_entities = sparql_result_to_df(res)\n",
    "\n",
    "# Second SPARQL Query\n",
    "# Open the file and read the SPARQL query\n",
    "with open(link_SPARQL_query_count_number_FNCT_tests, 'r') as file:\n",
    "    query = file.read()\n",
    "# Execute the SPARQL query\n",
    "res = triple_store.sparql(query)\n",
    "# Convert the result to a DataFrame\n",
    "data_count_number_of_FNCT_tests = sparql_result_to_df(res)\n",
    "\n",
    "# Third example SPARQL Query\n",
    "# Open the file and read the SPARQL query\n",
    "with open(link_SPARQL_query_select_all_materials_tested, 'r') as file:\n",
    "    query = file.read()\n",
    "# Execute the SPARQL query\n",
    "res = triple_store.sparql(query)\n",
    "# Convert the result to a DataFrame\n",
    "data_select_all_materials_tested = sparql_result_to_df(res)\n",
    "\n",
    "# Fourth example SPARQL Query\n",
    "# Open the file and read the SPARQL query\n",
    "with open(link_SPARQL_query_FNCT_results, 'r') as file:\n",
    "    query = file.read()\n",
    "# Execute the SPARQL query\n",
    "res = triple_store.sparql(query)\n",
    "# Convert the result to a DataFrame\n",
    "data_FNCT_results = sparql_result_to_df(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results \n",
    "\n",
    "For a depiction / visualization of results in table format, the module tabulate is used.\n",
    "Furthermore, as the SPARQL queries are defined by dedicated SPARQL query files, the headers of the result table can be read from the select clause in the queries, respectively. This way, the result can be double-checked manually and consistency is ensured (did the SPARQL query select statement really address the information I wanted to obtain?). Hence, the following code includes a read in of the information queried for (the terms / concepts / entities addressed using the select clause)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages (such as tabulate)\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "\n",
    "# First example SPARQL Query\n",
    "# Step 1: Read the first example SPARQL file content\n",
    "with open(link_SPARQL_query_count_all_entities, 'r') as file:\n",
    "    sparql_query = file.read()\n",
    "\n",
    "# Step 2: Extract the terms from the SELECT clause\n",
    "# This regular expression looks for the SELECT or SELECT DISTINCT clause and captures the terms.\n",
    "select_clause_match = re.search(r'SELECT\\s+(DISTINCT\\s+)?(.*?)\\s+WHERE', sparql_query, re.DOTALL)\n",
    "\n",
    "if select_clause_match:\n",
    "    select_clause = select_clause_match.group(2)  # Use group(2) to capture the variables\n",
    "    \n",
    "    # Extract variables that appear after AS ?variable or are directly selected as ?variable\n",
    "    headers = []\n",
    "    for match in re.findall(r'AS\\s+\\?(\\w+)|\\s+\\?(\\w+)', select_clause):\n",
    "        # match[0] captures the alias (after AS), match[1] captures direct selections\n",
    "        header = match[0] or match[1]\n",
    "        headers.append(header)\n",
    "else:\n",
    "    print(\"No headers were found. Please check the select clause within the SPARQL query.\")\n",
    "\n",
    "# Step 3: Use the headers in the tabulate print statement\n",
    "# Print the data with tabulate\n",
    "print(\"Number of all instances found in the triple store:\")\n",
    "print(tabulate(data_count_all_entities, headers=headers, tablefmt='psql', showindex=True))\n",
    "print(\"\\n\")  # Print a blank line between tables to enhance output readability\n",
    "\n",
    "\n",
    "# Second example SPARQL Query\n",
    "# Step 1: Read the first example SPARQL file content\n",
    "with open(link_SPARQL_query_count_number_FNCT_tests, 'r') as file:\n",
    "    sparql_query = file.read()\n",
    "\n",
    "# Step 2: Extract the terms from the SELECT clause\n",
    "# This regular expression looks for the SELECT or SELECT DISTINCT clause and captures the terms.\n",
    "select_clause_match = re.search(r'SELECT\\s+(DISTINCT\\s+)?(.*?)\\s+WHERE', sparql_query, re.DOTALL)\n",
    "\n",
    "if select_clause_match:\n",
    "    select_clause = select_clause_match.group(2)  # Use group(2) to capture the variables\n",
    "    \n",
    "    # Extract variables that appear after AS ?variable or are directly selected as ?variable\n",
    "    headers = []\n",
    "    for match in re.findall(r'AS\\s+\\?(\\w+)|\\s+\\?(\\w+)', select_clause):\n",
    "        # match[0] captures the alias (after AS), match[1] captures direct selections\n",
    "        header = match[0] or match[1]\n",
    "        headers.append(header)\n",
    "else:\n",
    "    print(\"No headers were found. Please check the select clause within the SPARQL query.\")\n",
    "\n",
    "# Step 3: Use the headers in the tabulate print statement\n",
    "# Print the data with tabulate\n",
    "print(\"Number of all instances of type FNCT in the dataset (number of FNCT tests included):\")\n",
    "print(tabulate(data_count_number_of_FNCT_tests, headers=headers, tablefmt='psql', showindex=True))\n",
    "print(\"\\n\")  # Print a blank line between tables to enhance output readability\n",
    "\n",
    "\n",
    "# Third example SPARQL Query\n",
    "# Step 1: Read the first example SPARQL file content\n",
    "with open(link_SPARQL_query_select_all_materials_tested, 'r') as file:\n",
    "    sparql_query = file.read()\n",
    "\n",
    "# Step 2: Extract the terms from the SELECT clause\n",
    "# This regular expression looks for the SELECT or SELECT DISTINCT clause and captures the terms.\n",
    "select_clause_match = re.search(r'SELECT\\s+(DISTINCT\\s+)?(.*?)\\s+WHERE', sparql_query, re.DOTALL)\n",
    "\n",
    "if select_clause_match:\n",
    "    select_clause = select_clause_match.group(2)  # Use group(2) to capture the variables\n",
    "    # Split the terms by whitespace and strip any leading or trailing spaces\n",
    "    headers = [term.strip().lstrip('?') for term in select_clause.split() if term.strip().startswith('?')]\n",
    "else:\n",
    "    print(\"No headers were found. Please check the select clause within the SPARQL query.\")\n",
    "\n",
    "# Step 3: Use the headers in the tabulate print statement\n",
    "# Print the data with tabulate\n",
    "print(\"Names of materials tested given in the triple store:\")\n",
    "print(tabulate(data_select_all_materials_tested, headers=headers, tablefmt='psql', showindex=True))\n",
    "print(\"\\n\")  # Print a blank line between tables to enhance output readability\n",
    "\n",
    "\n",
    "# Fourth example SPARQL Query\n",
    "# Step 1: Read the first example SPARQL file content\n",
    "with open(link_SPARQL_query_FNCT_results, 'r') as file:\n",
    "    sparql_query = file.read()\n",
    "\n",
    "# Step 2: Extract the terms from the SELECT clause\n",
    "# This regular expression looks for the SELECT or SELECT DISTINCT clause and captures the terms.\n",
    "select_clause_match = re.search(r'SELECT\\s+(DISTINCT\\s+)?(.*?)\\s+WHERE', sparql_query, re.DOTALL)\n",
    "\n",
    "if select_clause_match:\n",
    "    select_clause = select_clause_match.group(2)  # Use group(2) to capture the variables\n",
    "    # Split the terms by whitespace and strip any leading or trailing spaces\n",
    "    headers = [term.strip().lstrip('?') for term in select_clause.split() if term.strip().startswith('?')]\n",
    "else:\n",
    "    print(\"No headers were found. Please check the select clause within the SPARQL query.\")\n",
    "\n",
    "# Step 3: Use the headers in the tabulate print statement\n",
    "# Print the data with tabulate\n",
    "print(\"FNCT results including material names, media measured in, time to failure values and the measured stress values:\")\n",
    "print(tabulate(data_FNCT_results, headers=headers, tablefmt='psql', showindex=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
